// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: reads.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const getActiveValidatorsCount = `-- name: GetActiveValidatorsCount :one
SELECT count(DISTINCT vr.comet_address) as total
FROM etl_validator_registrations_v2 vr
WHERE vr.comet_address NOT IN (
    SELECT DISTINCT vd.comet_address 
    FROM etl_validator_deregistrations_v2 vd
)
`

// Get active validators count
func (q *Queries) GetActiveValidatorsCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getActiveValidatorsCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getAllValidatorsUptimeData = `-- name: GetAllValidatorsUptimeData :many
SELECT 
    vsr.node,
    vsr.sla_id,
    vsr.blocks_proposed,
    vsr.challenges_received,
    vsr.challenges_failed,
    vr.block_quota,
    vr.start_block,
    vr.end_block,
    vr.tx,
    vr.date_finalized
FROM v_sla_rollup_score vsr
JOIN v_sla_rollup vr ON vsr.sla_id = vr.id
WHERE vr.id IN (
    SELECT DISTINCT vr_inner.id 
    FROM v_sla_rollup vr_inner 
    ORDER BY vr_inner.date_finalized DESC 
    LIMIT $1
)
ORDER BY vsr.node, vr.date_finalized DESC
`

type GetAllValidatorsUptimeDataRow struct {
	Node               string           `json:"node"`
	SlaID              int32            `json:"sla_id"`
	BlocksProposed     int32            `json:"blocks_proposed"`
	ChallengesReceived int64            `json:"challenges_received"`
	ChallengesFailed   int32            `json:"challenges_failed"`
	BlockQuota         int32            `json:"block_quota"`
	StartBlock         int64            `json:"start_block"`
	EndBlock           int64            `json:"end_block"`
	Tx                 string           `json:"tx"`
	DateFinalized      pgtype.Timestamp `json:"date_finalized"`
}

// Get all validators uptime data using SLA rollup views
func (q *Queries) GetAllValidatorsUptimeData(ctx context.Context, limit int32) ([]GetAllValidatorsUptimeDataRow, error) {
	rows, err := q.db.Query(ctx, getAllValidatorsUptimeData, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAllValidatorsUptimeDataRow
	for rows.Next() {
		var i GetAllValidatorsUptimeDataRow
		if err := rows.Scan(
			&i.Node,
			&i.SlaID,
			&i.BlocksProposed,
			&i.ChallengesReceived,
			&i.ChallengesFailed,
			&i.BlockQuota,
			&i.StartBlock,
			&i.EndBlock,
			&i.Tx,
			&i.DateFinalized,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAvailableCities = `-- name: GetAvailableCities :many
SELECT 
    p.city,
    p.region,
    p.country,
    count(*) as play_count
FROM etl_plays_v2 p
WHERE p.city IS NOT NULL
    AND (NULLIF($1, '')::text IS NULL OR LOWER(p.country) = LOWER($1))
    AND (NULLIF($2, '')::text IS NULL OR LOWER(p.region) = LOWER($2))
GROUP BY p.city, p.region, p.country
ORDER BY count(*) DESC
LIMIT $3
`

type GetAvailableCitiesParams struct {
	Column1 interface{} `json:"column_1"`
	Column2 interface{} `json:"column_2"`
	Limit   int32       `json:"limit"`
}

type GetAvailableCitiesRow struct {
	City      pgtype.Text `json:"city"`
	Region    pgtype.Text `json:"region"`
	Country   pgtype.Text `json:"country"`
	PlayCount int64       `json:"play_count"`
}

// Get available cities using normalized schema
func (q *Queries) GetAvailableCities(ctx context.Context, arg GetAvailableCitiesParams) ([]GetAvailableCitiesRow, error) {
	rows, err := q.db.Query(ctx, getAvailableCities, arg.Column1, arg.Column2, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableCitiesRow
	for rows.Next() {
		var i GetAvailableCitiesRow
		if err := rows.Scan(
			&i.City,
			&i.Region,
			&i.Country,
			&i.PlayCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAvailableCountries = `-- name: GetAvailableCountries :many
SELECT 
    p.country,
    count(*) as play_count
FROM etl_plays_v2 p
WHERE p.country IS NOT NULL
GROUP BY p.country
ORDER BY count(*) DESC
LIMIT $1
`

type GetAvailableCountriesRow struct {
	Country   pgtype.Text `json:"country"`
	PlayCount int64       `json:"play_count"`
}

// Get available countries using normalized schema
func (q *Queries) GetAvailableCountries(ctx context.Context, limit int32) ([]GetAvailableCountriesRow, error) {
	rows, err := q.db.Query(ctx, getAvailableCountries, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableCountriesRow
	for rows.Next() {
		var i GetAvailableCountriesRow
		if err := rows.Scan(&i.Country, &i.PlayCount); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAvailableRegions = `-- name: GetAvailableRegions :many
SELECT 
    p.region,
    p.country,
    count(*) as play_count
FROM etl_plays_v2 p
WHERE p.region IS NOT NULL
    AND (NULLIF($1, '')::text IS NULL OR LOWER(p.country) = LOWER($1))
GROUP BY p.region, p.country
ORDER BY count(*) DESC
LIMIT $2
`

type GetAvailableRegionsParams struct {
	Column1 interface{} `json:"column_1"`
	Limit   int32       `json:"limit"`
}

type GetAvailableRegionsRow struct {
	Region    pgtype.Text `json:"region"`
	Country   pgtype.Text `json:"country"`
	PlayCount int64       `json:"play_count"`
}

// Get available regions using normalized schema
func (q *Queries) GetAvailableRegions(ctx context.Context, arg GetAvailableRegionsParams) ([]GetAvailableRegionsRow, error) {
	rows, err := q.db.Query(ctx, getAvailableRegions, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableRegionsRow
	for rows.Next() {
		var i GetAvailableRegionsRow
		if err := rows.Scan(&i.Region, &i.Country, &i.PlayCount); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBlockRangeByTime = `-- name: GetBlockRangeByTime :one
SELECT min(block_height) as start_block,
    max(block_height) as end_block
FROM etl_blocks
WHERE block_time BETWEEN $1 AND $2
`

type GetBlockRangeByTimeParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

type GetBlockRangeByTimeRow struct {
	StartBlock interface{} `json:"start_block"`
	EndBlock   interface{} `json:"end_block"`
}

func (q *Queries) GetBlockRangeByTime(ctx context.Context, arg GetBlockRangeByTimeParams) (GetBlockRangeByTimeRow, error) {
	row := q.db.QueryRow(ctx, getBlockRangeByTime, arg.BlockTime, arg.BlockTime_2)
	var i GetBlockRangeByTimeRow
	err := row.Scan(&i.StartBlock, &i.EndBlock)
	return i, err
}

const getBlockTransactions = `-- name: GetBlockTransactions :many
SELECT 
    t.tx_hash,
    t.tx_type,
    t.tx_index as index
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE b.block_height = $1
ORDER BY t.tx_index
`

type GetBlockTransactionsRow struct {
	TxHash string `json:"tx_hash"`
	TxType string `json:"tx_type"`
	Index  int32  `json:"index"`
}

// Get block transactions using normalized schema
func (q *Queries) GetBlockTransactions(ctx context.Context, blockHeight int64) ([]GetBlockTransactionsRow, error) {
	rows, err := q.db.Query(ctx, getBlockTransactions, blockHeight)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetBlockTransactionsRow
	for rows.Next() {
		var i GetBlockTransactionsRow
		if err := rows.Scan(&i.TxHash, &i.TxType, &i.Index); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBlocks = `-- name: GetBlocks :many
SELECT id, proposer_address, block_height, block_time, created_at, updated_at
FROM etl_blocks
WHERE block_height BETWEEN $1 AND $2
ORDER BY block_height DESC
`

type GetBlocksParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

// Get blocks using normalized schema
func (q *Queries) GetBlocks(ctx context.Context, arg GetBlocksParams) ([]EtlBlock, error) {
	rows, err := q.db.Query(ctx, getBlocks, arg.BlockHeight, arg.BlockHeight_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlBlock
	for rows.Next() {
		var i EtlBlock
		if err := rows.Scan(
			&i.ID,
			&i.ProposerAddress,
			&i.BlockHeight,
			&i.BlockTime,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEntityTypeStats24h = `-- name: GetEntityTypeStats24h :many
SELECT entity_type, action, count FROM v_entity_type_stats_24h
`

// Get entity type statistics for last 24h
func (q *Queries) GetEntityTypeStats24h(ctx context.Context) ([]VEntityTypeStats24h, error) {
	rows, err := q.db.Query(ctx, getEntityTypeStats24h)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []VEntityTypeStats24h
	for rows.Next() {
		var i VEntityTypeStats24h
		if err := rows.Scan(&i.EntityType, &i.Action, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getIndexedBlock = `-- name: GetIndexedBlock :one
SELECT id, proposer_address, block_height, block_time, created_at, updated_at
FROM etl_blocks
WHERE block_height = $1
`

func (q *Queries) GetIndexedBlock(ctx context.Context, blockHeight int64) (EtlBlock, error) {
	row := q.db.QueryRow(ctx, getIndexedBlock, blockHeight)
	var i EtlBlock
	err := row.Scan(
		&i.ID,
		&i.ProposerAddress,
		&i.BlockHeight,
		&i.BlockTime,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getLatestBlockInfo = `-- name: GetLatestBlockInfo :one
SELECT latest_indexed_height, latest_block_time, latest_proposer FROM v_latest_block_info
`

// Get latest block information
func (q *Queries) GetLatestBlockInfo(ctx context.Context) (VLatestBlockInfo, error) {
	row := q.db.QueryRow(ctx, getLatestBlockInfo)
	var i VLatestBlockInfo
	err := row.Scan(&i.LatestIndexedHeight, &i.LatestBlockTime, &i.LatestProposer)
	return i, err
}

const getLatestBlocks = `-- name: GetLatestBlocks :many
SELECT id, proposer_address, block_height, block_time, created_at, updated_at
FROM etl_blocks
ORDER BY block_height DESC
LIMIT $1 OFFSET $2
`

type GetLatestBlocksParams struct {
	Limit  int32 `json:"limit"`
	Offset int32 `json:"offset"`
}

func (q *Queries) GetLatestBlocks(ctx context.Context, arg GetLatestBlocksParams) ([]EtlBlock, error) {
	rows, err := q.db.Query(ctx, getLatestBlocks, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlBlock
	for rows.Next() {
		var i EtlBlock
		if err := rows.Scan(
			&i.ID,
			&i.ProposerAddress,
			&i.BlockHeight,
			&i.BlockTime,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getLatestIndexedBlock = `-- name: GetLatestIndexedBlock :one

SELECT block_height
FROM etl_blocks
ORDER BY id DESC
LIMIT 1
`

// Normalized read queries for ETL database
// Uses the new schema with proper JOIN operations for efficiency
// get latest indexed block height
func (q *Queries) GetLatestIndexedBlock(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getLatestIndexedBlock)
	var block_height int64
	err := row.Scan(&block_height)
	return block_height, err
}

const getLatestSLARollup = `-- name: GetLatestSLARollup :one
SELECT 
    sr.timestamp,
    sr.block_start,
    sr.block_end,
    b.block_height,
    t.tx_hash
FROM etl_sla_rollups_v2 sr
JOIN etl_transactions_v2 t ON sr.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
ORDER BY sr.timestamp DESC
LIMIT 1
`

type GetLatestSLARollupRow struct {
	Timestamp   pgtype.Timestamp `json:"timestamp"`
	BlockStart  int64            `json:"block_start"`
	BlockEnd    int64            `json:"block_end"`
	BlockHeight int64            `json:"block_height"`
	TxHash      string           `json:"tx_hash"`
}

// Get latest SLA rollup using normalized schema
func (q *Queries) GetLatestSLARollup(ctx context.Context) (GetLatestSLARollupRow, error) {
	row := q.db.QueryRow(ctx, getLatestSLARollup)
	var i GetLatestSLARollupRow
	err := row.Scan(
		&i.Timestamp,
		&i.BlockStart,
		&i.BlockEnd,
		&i.BlockHeight,
		&i.TxHash,
	)
	return i, err
}

const getLatestTransactions = `-- name: GetLatestTransactions :many
SELECT 
    t.id,
    t.tx_hash,
    b.block_height,
    t.tx_index as index,
    t.tx_type,
    b.block_time,
    b.proposer_address,
    t.created_at
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
ORDER BY t.id DESC
LIMIT $1 OFFSET $2
`

type GetLatestTransactionsParams struct {
	Limit  int32 `json:"limit"`
	Offset int32 `json:"offset"`
}

type GetLatestTransactionsRow struct {
	ID              int32            `json:"id"`
	TxHash          string           `json:"tx_hash"`
	BlockHeight     int64            `json:"block_height"`
	Index           int32            `json:"index"`
	TxType          string           `json:"tx_type"`
	BlockTime       pgtype.Timestamp `json:"block_time"`
	ProposerAddress string           `json:"proposer_address"`
	CreatedAt       pgtype.Timestamp `json:"created_at"`
}

// Get latest transactions with block info using normalized schema
func (q *Queries) GetLatestTransactions(ctx context.Context, arg GetLatestTransactionsParams) ([]GetLatestTransactionsRow, error) {
	rows, err := q.db.Query(ctx, getLatestTransactions, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetLatestTransactionsRow
	for rows.Next() {
		var i GetLatestTransactionsRow
		if err := rows.Scan(
			&i.ID,
			&i.TxHash,
			&i.BlockHeight,
			&i.Index,
			&i.TxType,
			&i.BlockTime,
			&i.ProposerAddress,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getManageEntitiesByTxHash = `-- name: GetManageEntitiesByTxHash :many
SELECT 
    a.address,
    me.entity_type,
    me.entity_id,
    me.action,
    me.metadata,
    me.signature,
    sa.address as signer,
    me.nonce
FROM etl_manage_entities_v2 me
JOIN etl_addresses a ON me.address_id = a.id
JOIN etl_addresses sa ON me.signer_address_id = sa.id
JOIN etl_transactions_v2 t ON me.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetManageEntitiesByTxHashRow struct {
	Address    string      `json:"address"`
	EntityType string      `json:"entity_type"`
	EntityID   int64       `json:"entity_id"`
	Action     string      `json:"action"`
	Metadata   pgtype.Text `json:"metadata"`
	Signature  string      `json:"signature"`
	Signer     string      `json:"signer"`
	Nonce      string      `json:"nonce"`
}

// Get manage entities by tx hash using normalized schema
func (q *Queries) GetManageEntitiesByTxHash(ctx context.Context, txHash string) ([]GetManageEntitiesByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getManageEntitiesByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetManageEntitiesByTxHashRow
	for rows.Next() {
		var i GetManageEntitiesByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.EntityType,
			&i.EntityID,
			&i.Action,
			&i.Metadata,
			&i.Signature,
			&i.Signer,
			&i.Nonce,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getNetworkRates = `-- name: GetNetworkRates :one
SELECT 
    blocks_per_second,
    transactions_per_second,
    COALESCE(block_count, 0) as block_count,
    COALESCE(transaction_count, 0) as transaction_count,
    start_time,
    end_time
FROM v_network_rates
`

// Get network rates (BPS/TPS) based on latest SLA rollup
func (q *Queries) GetNetworkRates(ctx context.Context) (VNetworkRate, error) {
	row := q.db.QueryRow(ctx, getNetworkRates)
	var i VNetworkRate
	err := row.Scan(
		&i.BlocksPerSecond,
		&i.TransactionsPerSecond,
		&i.BlockCount,
		&i.TransactionCount,
		&i.StartTime,
		&i.EndTime,
	)
	return i, err
}

const getPlayCountByAddress = `-- name: GetPlayCountByAddress :one
SELECT count(*) as play_count
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
WHERE a.address = $1
`

// Get play count by address
func (q *Queries) GetPlayCountByAddress(ctx context.Context, address string) (int64, error) {
	row := q.db.QueryRow(ctx, getPlayCountByAddress, address)
	var play_count int64
	err := row.Scan(&play_count)
	return play_count, err
}

const getPlayCountByTrack = `-- name: GetPlayCountByTrack :one
SELECT count(*) as play_count
FROM etl_plays_v2
WHERE track_id = $1
`

// Get play count by track
func (q *Queries) GetPlayCountByTrack(ctx context.Context, trackID string) (int64, error) {
	row := q.db.QueryRow(ctx, getPlayCountByTrack, trackID)
	var play_count int64
	err := row.Scan(&play_count)
	return play_count, err
}

const getPlays = `-- name: GetPlays :many
SELECT 
    a.address,
    p.track_id,
    EXTRACT(epoch FROM p.played_at)::bigint as timestamp,
    p.city,
    p.country,
    p.region,
    b.block_height,
    t.tx_hash
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
JOIN etl_transactions_v2 t ON p.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
WHERE b.block_height BETWEEN $1 AND $2
ORDER BY p.played_at DESC
LIMIT $3 OFFSET $4
`

type GetPlaysParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
	Limit         int32 `json:"limit"`
	Offset        int32 `json:"offset"`
}

type GetPlaysRow struct {
	Address     string      `json:"address"`
	TrackID     string      `json:"track_id"`
	Timestamp   int64       `json:"timestamp"`
	City        pgtype.Text `json:"city"`
	Country     pgtype.Text `json:"country"`
	Region      pgtype.Text `json:"region"`
	BlockHeight int64       `json:"block_height"`
	TxHash      string      `json:"tx_hash"`
}

// Get all plays using normalized schema
func (q *Queries) GetPlays(ctx context.Context, arg GetPlaysParams) ([]GetPlaysRow, error) {
	rows, err := q.db.Query(ctx, getPlays,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysRow
	for rows.Next() {
		var i GetPlaysRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByAddress = `-- name: GetPlaysByAddress :many
SELECT 
    a.address,
    p.track_id,
    EXTRACT(epoch FROM p.played_at)::bigint as timestamp,
    p.city,
    p.country,
    p.region,
    b.block_height,
    t.tx_hash
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
JOIN etl_transactions_v2 t ON p.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
WHERE a.address = $1
    AND b.block_height BETWEEN $2 AND $3
ORDER BY p.played_at DESC
LIMIT $4 OFFSET $5
`

type GetPlaysByAddressParams struct {
	Address       string `json:"address"`
	BlockHeight   int64  `json:"block_height"`
	BlockHeight_2 int64  `json:"block_height_2"`
	Limit         int32  `json:"limit"`
	Offset        int32  `json:"offset"`
}

type GetPlaysByAddressRow struct {
	Address     string      `json:"address"`
	TrackID     string      `json:"track_id"`
	Timestamp   int64       `json:"timestamp"`
	City        pgtype.Text `json:"city"`
	Country     pgtype.Text `json:"country"`
	Region      pgtype.Text `json:"region"`
	BlockHeight int64       `json:"block_height"`
	TxHash      string      `json:"tx_hash"`
}

// Get plays by address using normalized schema
func (q *Queries) GetPlaysByAddress(ctx context.Context, arg GetPlaysByAddressParams) ([]GetPlaysByAddressRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByAddress,
		arg.Address,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByAddressRow
	for rows.Next() {
		var i GetPlaysByAddressRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByLocation = `-- name: GetPlaysByLocation :many
SELECT 
    t.tx_hash,
    a.address,
    p.track_id,
    p.played_at,
    p.city,
    p.region,
    p.country,
    p.played_at as created_at
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
JOIN etl_transactions_v2 t ON p.transaction_id = t.id
WHERE (NULLIF($1, '')::text IS NULL OR LOWER(p.city) = LOWER($1))
    AND (NULLIF($2, '')::text IS NULL OR LOWER(p.region) = LOWER($2))
    AND (NULLIF($3, '')::text IS NULL OR LOWER(p.country) = LOWER($3))
ORDER BY p.played_at DESC
LIMIT $4
`

type GetPlaysByLocationParams struct {
	Column1 interface{} `json:"column_1"`
	Column2 interface{} `json:"column_2"`
	Column3 interface{} `json:"column_3"`
	Limit   int32       `json:"limit"`
}

type GetPlaysByLocationRow struct {
	TxHash    string           `json:"tx_hash"`
	Address   string           `json:"address"`
	TrackID   string           `json:"track_id"`
	PlayedAt  pgtype.Timestamp `json:"played_at"`
	City      pgtype.Text      `json:"city"`
	Region    pgtype.Text      `json:"region"`
	Country   pgtype.Text      `json:"country"`
	CreatedAt pgtype.Timestamp `json:"created_at"`
}

// Get plays by location using normalized schema
func (q *Queries) GetPlaysByLocation(ctx context.Context, arg GetPlaysByLocationParams) ([]GetPlaysByLocationRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByLocation,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByLocationRow
	for rows.Next() {
		var i GetPlaysByLocationRow
		if err := rows.Scan(
			&i.TxHash,
			&i.Address,
			&i.TrackID,
			&i.PlayedAt,
			&i.City,
			&i.Region,
			&i.Country,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByTrack = `-- name: GetPlaysByTrack :many
SELECT 
    a.address,
    p.track_id,
    EXTRACT(epoch FROM p.played_at)::bigint as timestamp,
    p.city,
    p.country,
    p.region,
    b.block_height,
    t.tx_hash
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
JOIN etl_transactions_v2 t ON p.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
WHERE p.track_id = $1
    AND b.block_height BETWEEN $2 AND $3
ORDER BY p.played_at DESC
LIMIT $4 OFFSET $5
`

type GetPlaysByTrackParams struct {
	TrackID       string `json:"track_id"`
	BlockHeight   int64  `json:"block_height"`
	BlockHeight_2 int64  `json:"block_height_2"`
	Limit         int32  `json:"limit"`
	Offset        int32  `json:"offset"`
}

type GetPlaysByTrackRow struct {
	Address     string      `json:"address"`
	TrackID     string      `json:"track_id"`
	Timestamp   int64       `json:"timestamp"`
	City        pgtype.Text `json:"city"`
	Country     pgtype.Text `json:"country"`
	Region      pgtype.Text `json:"region"`
	BlockHeight int64       `json:"block_height"`
	TxHash      string      `json:"tx_hash"`
}

// Get plays by track using normalized schema
func (q *Queries) GetPlaysByTrack(ctx context.Context, arg GetPlaysByTrackParams) ([]GetPlaysByTrackRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByTrack,
		arg.TrackID,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByTrackRow
	for rows.Next() {
		var i GetPlaysByTrackRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByTxHash = `-- name: GetPlaysByTxHash :many
SELECT 
    a.address,
    p.track_id,
    EXTRACT(epoch FROM p.played_at)::bigint as timestamp,
    p.city,
    p.region,
    p.country
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
JOIN etl_transactions_v2 t ON p.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetPlaysByTxHashRow struct {
	Address   string      `json:"address"`
	TrackID   string      `json:"track_id"`
	Timestamp int64       `json:"timestamp"`
	City      pgtype.Text `json:"city"`
	Region    pgtype.Text `json:"region"`
	Country   pgtype.Text `json:"country"`
}

// Get plays by tx hash using normalized schema
func (q *Queries) GetPlaysByTxHash(ctx context.Context, txHash string) ([]GetPlaysByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByTxHashRow
	for rows.Next() {
		var i GetPlaysByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Region,
			&i.Country,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysCount = `-- name: GetPlaysCount :one
SELECT count(*) as total
FROM etl_plays_v2 p
JOIN etl_addresses a ON p.address_id = a.id
WHERE ($1::text IS NULL OR a.address = $1)
    AND ($2::text IS NULL OR p.track_id = $2)
    AND ($3::timestamp IS NULL OR $4::timestamp IS NULL OR p.played_at BETWEEN $3 AND $4)
`

type GetPlaysCountParams struct {
	Column1 string           `json:"column_1"`
	Column2 string           `json:"column_2"`
	Column3 pgtype.Timestamp `json:"column_3"`
	Column4 pgtype.Timestamp `json:"column_4"`
}

// Get total count of plays with filtering (normalized schema)
func (q *Queries) GetPlaysCount(ctx context.Context, arg GetPlaysCountParams) (int64, error) {
	row := q.db.QueryRow(ctx, getPlaysCount,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
	)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getPlaysLocationDistribution24h = `-- name: GetPlaysLocationDistribution24h :many
SELECT country, region, city, play_count FROM v_plays_by_location_24h
LIMIT $1
`

// Get geographic distribution of plays
func (q *Queries) GetPlaysLocationDistribution24h(ctx context.Context, limit int32) ([]VPlaysByLocation24h, error) {
	rows, err := q.db.Query(ctx, getPlaysLocationDistribution24h, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []VPlaysByLocation24h
	for rows.Next() {
		var i VPlaysByLocation24h
		if err := rows.Scan(
			&i.Country,
			&i.Region,
			&i.City,
			&i.PlayCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysStats = `-- name: GetPlaysStats :one
SELECT total_plays, total_plays_24h, total_plays_7d, total_plays_30d, unique_players_all_time, unique_players_24h FROM v_plays_stats
`

// Get plays statistics
func (q *Queries) GetPlaysStats(ctx context.Context) (VPlaysStat, error) {
	row := q.db.QueryRow(ctx, getPlaysStats)
	var i VPlaysStat
	err := row.Scan(
		&i.TotalPlays,
		&i.TotalPlays24h,
		&i.TotalPlays7d,
		&i.TotalPlays30d,
		&i.UniquePlayersAllTime,
		&i.UniquePlayers24h,
	)
	return i, err
}

const getRelationTypesByAddress = `-- name: GetRelationTypesByAddress :many
SELECT DISTINCT me.entity_type as relation_type
FROM etl_manage_entities_v2 me
JOIN etl_addresses a ON me.address_id = a.id
WHERE a.address = $1
`

// Get relation types by address (placeholder for compatibility)
func (q *Queries) GetRelationTypesByAddress(ctx context.Context, address string) ([]string, error) {
	rows, err := q.db.Query(ctx, getRelationTypesByAddress, address)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var relation_type string
		if err := rows.Scan(&relation_type); err != nil {
			return nil, err
		}
		items = append(items, relation_type)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getReleasesByTxHash = `-- name: GetReleasesByTxHash :many
SELECT 
    r.release_data
FROM etl_releases_v2 r
JOIN etl_transactions_v2 t ON r.transaction_id = t.id
WHERE t.tx_hash = $1
`

// Get releases by tx hash using normalized schema
func (q *Queries) GetReleasesByTxHash(ctx context.Context, txHash string) ([][]byte, error) {
	rows, err := q.db.Query(ctx, getReleasesByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items [][]byte
	for rows.Next() {
		var release_data []byte
		if err := rows.Scan(&release_data); err != nil {
			return nil, err
		}
		items = append(items, release_data)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSlaNodeReportsByTxHash = `-- name: GetSlaNodeReportsByTxHash :many
SELECT 
    a.address,
    snr.num_blocks_proposed
FROM etl_sla_node_reports_v2 snr
JOIN etl_addresses a ON snr.address_id = a.id
JOIN etl_sla_rollups_v2 sr ON snr.sla_rollup_id = sr.id
JOIN etl_transactions_v2 t ON sr.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetSlaNodeReportsByTxHashRow struct {
	Address           string `json:"address"`
	NumBlocksProposed int32  `json:"num_blocks_proposed"`
}

// Get SLA node reports by tx hash using normalized schema
func (q *Queries) GetSlaNodeReportsByTxHash(ctx context.Context, txHash string) ([]GetSlaNodeReportsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getSlaNodeReportsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetSlaNodeReportsByTxHashRow
	for rows.Next() {
		var i GetSlaNodeReportsByTxHashRow
		if err := rows.Scan(&i.Address, &i.NumBlocksProposed); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSlaRollupsByTxHash = `-- name: GetSlaRollupsByTxHash :many
SELECT 
    sr.timestamp,
    sr.block_start,
    sr.block_end
FROM etl_sla_rollups_v2 sr
JOIN etl_transactions_v2 t ON sr.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetSlaRollupsByTxHashRow struct {
	Timestamp  pgtype.Timestamp `json:"timestamp"`
	BlockStart int64            `json:"block_start"`
	BlockEnd   int64            `json:"block_end"`
}

// Get SLA rollups by tx hash using normalized schema
func (q *Queries) GetSlaRollupsByTxHash(ctx context.Context, txHash string) ([]GetSlaRollupsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getSlaRollupsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetSlaRollupsByTxHashRow
	for rows.Next() {
		var i GetSlaRollupsByTxHashRow
		if err := rows.Scan(&i.Timestamp, &i.BlockStart, &i.BlockEnd); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStorageProofVerificationsByTxHash = `-- name: GetStorageProofVerificationsByTxHash :many
SELECT 
    spv.height,
    spv.proof
FROM etl_storage_proof_verifications_v2 spv
JOIN etl_transactions_v2 t ON spv.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetStorageProofVerificationsByTxHashRow struct {
	Height int64  `json:"height"`
	Proof  []byte `json:"proof"`
}

// Get storage proof verifications by tx hash using normalized schema
func (q *Queries) GetStorageProofVerificationsByTxHash(ctx context.Context, txHash string) ([]GetStorageProofVerificationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getStorageProofVerificationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetStorageProofVerificationsByTxHashRow
	for rows.Next() {
		var i GetStorageProofVerificationsByTxHashRow
		if err := rows.Scan(&i.Height, &i.Proof); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStorageProofsByTxHash = `-- name: GetStorageProofsByTxHash :many
SELECT 
    a.address,
    sp.height,
    sp.prover_addresses,
    sp.cid,
    sp.proof_signature
FROM etl_storage_proofs_v2 sp
JOIN etl_addresses a ON sp.address_id = a.id
JOIN etl_transactions_v2 t ON sp.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetStorageProofsByTxHashRow struct {
	Address         string   `json:"address"`
	Height          int64    `json:"height"`
	ProverAddresses []string `json:"prover_addresses"`
	Cid             string   `json:"cid"`
	ProofSignature  []byte   `json:"proof_signature"`
}

// Get storage proofs by tx hash using normalized schema
func (q *Queries) GetStorageProofsByTxHash(ctx context.Context, txHash string) ([]GetStorageProofsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getStorageProofsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetStorageProofsByTxHashRow
	for rows.Next() {
		var i GetStorageProofsByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.Height,
			&i.ProverAddresses,
			&i.Cid,
			&i.ProofSignature,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSyncStatus = `-- name: GetSyncStatus :one
SELECT 
    lbi.latest_indexed_height,
    lbi.latest_block_time,
    CASE 
        WHEN lbi.latest_indexed_height < $1 - 100 THEN true 
        ELSE false 
    END as is_syncing,
    $1 as latest_chain_height,
    $1 - lbi.latest_indexed_height as block_delta
FROM v_latest_block_info lbi
`

type GetSyncStatusRow struct {
	LatestIndexedHeight int64            `json:"latest_indexed_height"`
	LatestBlockTime     pgtype.Timestamp `json:"latest_block_time"`
	IsSyncing           bool             `json:"is_syncing"`
	LatestChainHeight   interface{}      `json:"latest_chain_height"`
	BlockDelta          int32            `json:"block_delta"`
}

// Get sync status by comparing latest indexed vs chain height
func (q *Queries) GetSyncStatus(ctx context.Context, dollar_1 interface{}) (GetSyncStatusRow, error) {
	row := q.db.QueryRow(ctx, getSyncStatus, dollar_1)
	var i GetSyncStatusRow
	err := row.Scan(
		&i.LatestIndexedHeight,
		&i.LatestBlockTime,
		&i.IsSyncing,
		&i.LatestChainHeight,
		&i.BlockDelta,
	)
	return i, err
}

const getTopTracks24h = `-- name: GetTopTracks24h :many
SELECT track_id, play_count, unique_players FROM v_top_tracks_24h
LIMIT $1
`

// Get top tracks in last 24h
func (q *Queries) GetTopTracks24h(ctx context.Context, limit int32) ([]VTopTracks24h, error) {
	rows, err := q.db.Query(ctx, getTopTracks24h, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []VTopTracks24h
	for rows.Next() {
		var i VTopTracks24h
		if err := rows.Scan(&i.TrackID, &i.PlayCount, &i.UniquePlayers); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTotalBlocksCount = `-- name: GetTotalBlocksCount :one
SELECT count(*) as total
FROM etl_blocks
`

func (q *Queries) GetTotalBlocksCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getTotalBlocksCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTotalTransactionsCount = `-- name: GetTotalTransactionsCount :one
SELECT count(*) as total
FROM etl_transactions_v2
`

func (q *Queries) GetTotalTransactionsCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getTotalTransactionsCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTransaction = `-- name: GetTransaction :one
SELECT 
    t.tx_hash,
    t.tx_type,
    b.block_height,
    t.tx_index as index,
    b.block_time,
    b.proposer_address
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE t.tx_hash = $1
ORDER BY b.block_height DESC, t.tx_index DESC
LIMIT 1
`

type GetTransactionRow struct {
	TxHash          string           `json:"tx_hash"`
	TxType          string           `json:"tx_type"`
	BlockHeight     int64            `json:"block_height"`
	Index           int32            `json:"index"`
	BlockTime       pgtype.Timestamp `json:"block_time"`
	ProposerAddress string           `json:"proposer_address"`
}

// Get transaction using normalized schema
func (q *Queries) GetTransaction(ctx context.Context, txHash string) (GetTransactionRow, error) {
	row := q.db.QueryRow(ctx, getTransaction, txHash)
	var i GetTransactionRow
	err := row.Scan(
		&i.TxHash,
		&i.TxType,
		&i.BlockHeight,
		&i.Index,
		&i.BlockTime,
		&i.ProposerAddress,
	)
	return i, err
}

const getTransactionStats = `-- name: GetTransactionStats :one

SELECT total_transactions, total_transactions_24h, total_transactions_previous_24h, total_transactions_7d, total_transactions_30d FROM v_transaction_stats
`

// Statistics queries using PostgreSQL views
// These queries leverage database views for efficient stats calculation
// Get overall transaction statistics
func (q *Queries) GetTransactionStats(ctx context.Context) (VTransactionStat, error) {
	row := q.db.QueryRow(ctx, getTransactionStats)
	var i VTransactionStat
	err := row.Scan(
		&i.TotalTransactions,
		&i.TotalTransactions24h,
		&i.TotalTransactionsPrevious24h,
		&i.TotalTransactions7d,
		&i.TotalTransactions30d,
	)
	return i, err
}

const getTransactionTypeBreakdown = `-- name: GetTransactionTypeBreakdown :many
SELECT 
    t.tx_type as type,
    count(*) as count
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE b.block_time BETWEEN $1 AND $2
GROUP BY t.tx_type
ORDER BY count(*) DESC
`

type GetTransactionTypeBreakdownParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

type GetTransactionTypeBreakdownRow struct {
	Type  string `json:"type"`
	Count int64  `json:"count"`
}

// Get transaction type breakdown
func (q *Queries) GetTransactionTypeBreakdown(ctx context.Context, arg GetTransactionTypeBreakdownParams) ([]GetTransactionTypeBreakdownRow, error) {
	rows, err := q.db.Query(ctx, getTransactionTypeBreakdown, arg.BlockTime, arg.BlockTime_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetTransactionTypeBreakdownRow
	for rows.Next() {
		var i GetTransactionTypeBreakdownRow
		if err := rows.Scan(&i.Type, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTransactionTypeBreakdown24h = `-- name: GetTransactionTypeBreakdown24h :many
SELECT type, count FROM v_transaction_type_breakdown_24h
`

// Get transaction type breakdown for last 24h
func (q *Queries) GetTransactionTypeBreakdown24h(ctx context.Context) ([]VTransactionTypeBreakdown24h, error) {
	rows, err := q.db.Query(ctx, getTransactionTypeBreakdown24h)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []VTransactionTypeBreakdown24h
	for rows.Next() {
		var i VTransactionTypeBreakdown24h
		if err := rows.Scan(&i.Type, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTransactionsByAddress = `-- name: GetTransactionsByAddress :many
WITH address_transactions AS (
    -- Play transactions
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        a.address,
        'play' as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_plays_v2 p ON p.transaction_id = t.id
    JOIN etl_addresses a ON p.address_id = a.id
    WHERE LOWER(a.address) = LOWER($1)
    
    UNION ALL
    
    -- Manage entity transactions
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        a.address,
        me.action || '_' || me.entity_type as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_manage_entities_v2 me ON me.transaction_id = t.id
    JOIN etl_addresses a ON me.address_id = a.id
    WHERE LOWER(a.address) = LOWER($1)
    
    UNION ALL
    
    -- Validator registration transactions
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        a.address,
        'validator_registration' as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_validator_registrations_v2 vr ON vr.transaction_id = t.id
    JOIN etl_addresses a ON vr.address_id = a.id
    WHERE LOWER(a.address) = LOWER($1)
    
    UNION ALL
    
    -- Validator deregistration transactions (by comet_address)
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        vd.comet_address as address,
        'validator_deregistration' as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_validator_deregistrations_v2 vd ON vd.transaction_id = t.id
    WHERE LOWER(vd.comet_address) = LOWER($1)
    
    UNION ALL
    
    -- Storage proof transactions
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        a.address,
        'storage_proof' as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_storage_proofs_v2 sp ON sp.transaction_id = t.id
    JOIN etl_addresses a ON sp.address_id = a.id
    WHERE LOWER(a.address) = LOWER($1)
    
    UNION ALL
    
    -- SLA node report transactions
    SELECT 
        t.tx_hash,
        t.tx_type,
        b.block_height,
        t.tx_index as index,
        a.address,
        'sla_node_report' as relation_type,
        b.block_time
    FROM etl_transactions_v2 t
    JOIN etl_blocks b ON t.block_id = b.id
    JOIN etl_sla_rollups_v2 sr ON sr.transaction_id = t.id
    JOIN etl_sla_node_reports_v2 snr ON snr.sla_rollup_id = sr.id
    JOIN etl_addresses a ON snr.address_id = a.id
    WHERE LOWER(a.address) = LOWER($1)
)
SELECT 
    tx_hash,
    tx_type,
    block_height,
    index,
    address,
    relation_type,
    block_time
FROM address_transactions
WHERE ($4::text = '' OR relation_type = $4)
    AND ($5::timestamp IS NULL OR block_time >= $5)
    AND ($6::timestamp IS NULL OR block_time <= $6)
ORDER BY block_height DESC, index DESC
LIMIT $2 OFFSET $3
`

type GetTransactionsByAddressParams struct {
	Lower   string           `json:"lower"`
	Limit   int32            `json:"limit"`
	Offset  int32            `json:"offset"`
	Column4 string           `json:"column_4"`
	Column5 pgtype.Timestamp `json:"column_5"`
	Column6 pgtype.Timestamp `json:"column_6"`
}

type GetTransactionsByAddressRow struct {
	TxHash       string           `json:"tx_hash"`
	TxType       string           `json:"tx_type"`
	BlockHeight  int64            `json:"block_height"`
	Index        int32            `json:"index"`
	Address      string           `json:"address"`
	RelationType string           `json:"relation_type"`
	BlockTime    pgtype.Timestamp `json:"block_time"`
}

// Get transactions by address using normalized schema (complex CTE query)
func (q *Queries) GetTransactionsByAddress(ctx context.Context, arg GetTransactionsByAddressParams) ([]GetTransactionsByAddressRow, error) {
	rows, err := q.db.Query(ctx, getTransactionsByAddress,
		arg.Lower,
		arg.Limit,
		arg.Offset,
		arg.Column4,
		arg.Column5,
		arg.Column6,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetTransactionsByAddressRow
	for rows.Next() {
		var i GetTransactionsByAddressRow
		if err := rows.Scan(
			&i.TxHash,
			&i.TxType,
			&i.BlockHeight,
			&i.Index,
			&i.Address,
			&i.RelationType,
			&i.BlockTime,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTransactionsCount = `-- name: GetTransactionsCount :one
SELECT count(*) as total
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE b.block_height BETWEEN $1 AND $2
`

type GetTransactionsCountParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

// Get transactions count in block range
func (q *Queries) GetTransactionsCount(ctx context.Context, arg GetTransactionsCountParams) (int64, error) {
	row := q.db.QueryRow(ctx, getTransactionsCount, arg.BlockHeight, arg.BlockHeight_2)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTransactionsCountTimeRange = `-- name: GetTransactionsCountTimeRange :one
SELECT count(*) as total
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE b.block_time BETWEEN $1 AND $2
`

type GetTransactionsCountTimeRangeParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

// Get transactions count in time range
func (q *Queries) GetTransactionsCountTimeRange(ctx context.Context, arg GetTransactionsCountTimeRangeParams) (int64, error) {
	row := q.db.QueryRow(ctx, getTransactionsCountTimeRange, arg.BlockTime, arg.BlockTime_2)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getValidatorDeregistrations = `-- name: GetValidatorDeregistrations :many
SELECT 
    vd.comet_address,
    vd.comet_pubkey,
    b.block_height,
    t.tx_hash
FROM etl_validator_deregistrations_v2 vd
JOIN etl_transactions_v2 t ON vd.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
`

type GetValidatorDeregistrationsRow struct {
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// Get validator deregistrations using normalized schema
func (q *Queries) GetValidatorDeregistrations(ctx context.Context) ([]GetValidatorDeregistrationsRow, error) {
	rows, err := q.db.Query(ctx, getValidatorDeregistrations)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorDeregistrationsRow
	for rows.Next() {
		var i GetValidatorDeregistrationsRow
		if err := rows.Scan(
			&i.CometAddress,
			&i.CometPubkey,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorDeregistrationsByTxHash = `-- name: GetValidatorDeregistrationsByTxHash :many
SELECT 
    vd.comet_address,
    vd.comet_pubkey
FROM etl_validator_deregistrations_v2 vd
JOIN etl_transactions_v2 t ON vd.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetValidatorDeregistrationsByTxHashRow struct {
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
}

// Get validator deregistrations by tx hash using normalized schema
func (q *Queries) GetValidatorDeregistrationsByTxHash(ctx context.Context, txHash string) ([]GetValidatorDeregistrationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getValidatorDeregistrationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorDeregistrationsByTxHashRow
	for rows.Next() {
		var i GetValidatorDeregistrationsByTxHashRow
		if err := rows.Scan(&i.CometAddress, &i.CometPubkey); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorEndpointByAddress = `-- name: GetValidatorEndpointByAddress :one
SELECT endpoint, comet_address
FROM etl_validator_registrations_v2 vr
JOIN etl_addresses a ON vr.address_id = a.id
WHERE a.address = $1 OR vr.comet_address = $1
ORDER BY vr.id DESC
LIMIT 1
`

type GetValidatorEndpointByAddressRow struct {
	Endpoint     string `json:"endpoint"`
	CometAddress string `json:"comet_address"`
}

// Get validator endpoint by address for uptime display
func (q *Queries) GetValidatorEndpointByAddress(ctx context.Context, address string) (GetValidatorEndpointByAddressRow, error) {
	row := q.db.QueryRow(ctx, getValidatorEndpointByAddress, address)
	var i GetValidatorEndpointByAddressRow
	err := row.Scan(&i.Endpoint, &i.CometAddress)
	return i, err
}

const getValidatorRegistrations = `-- name: GetValidatorRegistrations :many
SELECT DISTINCT ON (a.address) 
    a.address,
    vr.endpoint,
    vr.comet_address,
    vr.comet_pubkey,
    vr.eth_block,
    vr.node_type,
    vr.spid,
    vr.voting_power,
    b.block_height,
    t.tx_hash
FROM etl_validator_registrations_v2 vr
JOIN etl_addresses a ON vr.address_id = a.id
JOIN etl_transactions_v2 t ON vr.transaction_id = t.id
JOIN etl_blocks b ON t.block_id = b.id
WHERE ($1::text IS NULL OR LOWER(vr.endpoint) LIKE '%' || LOWER($1) || '%')
ORDER BY a.address, b.block_height DESC
`

type GetValidatorRegistrationsRow struct {
	Address      string `json:"address"`
	Endpoint     string `json:"endpoint"`
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	Spid         string `json:"spid"`
	VotingPower  int64  `json:"voting_power"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// Get validator registrations using normalized schema
func (q *Queries) GetValidatorRegistrations(ctx context.Context, dollar_1 string) ([]GetValidatorRegistrationsRow, error) {
	rows, err := q.db.Query(ctx, getValidatorRegistrations, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorRegistrationsRow
	for rows.Next() {
		var i GetValidatorRegistrationsRow
		if err := rows.Scan(
			&i.Address,
			&i.Endpoint,
			&i.CometAddress,
			&i.CometPubkey,
			&i.EthBlock,
			&i.NodeType,
			&i.Spid,
			&i.VotingPower,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorRegistrationsByTxHash = `-- name: GetValidatorRegistrationsByTxHash :many
SELECT 
    a.address,
    vr.comet_address,
    vr.eth_block,
    vr.node_type,
    vr.spid,
    vr.comet_pubkey,
    vr.voting_power
FROM etl_validator_registrations_v2 vr
JOIN etl_addresses a ON vr.address_id = a.id
JOIN etl_transactions_v2 t ON vr.transaction_id = t.id
WHERE t.tx_hash = $1
`

type GetValidatorRegistrationsByTxHashRow struct {
	Address      string `json:"address"`
	CometAddress string `json:"comet_address"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	Spid         string `json:"spid"`
	CometPubkey  []byte `json:"comet_pubkey"`
	VotingPower  int64  `json:"voting_power"`
}

// Get validator registrations by tx hash using normalized schema
func (q *Queries) GetValidatorRegistrationsByTxHash(ctx context.Context, txHash string) ([]GetValidatorRegistrationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getValidatorRegistrationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorRegistrationsByTxHashRow
	for rows.Next() {
		var i GetValidatorRegistrationsByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.CometAddress,
			&i.EthBlock,
			&i.NodeType,
			&i.Spid,
			&i.CometPubkey,
			&i.VotingPower,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorStats = `-- name: GetValidatorStats :one
SELECT total_registered_validators, active_validators, deregistered_validators FROM v_validator_stats
`

// Get validator statistics
func (q *Queries) GetValidatorStats(ctx context.Context) (VValidatorStat, error) {
	row := q.db.QueryRow(ctx, getValidatorStats)
	var i VValidatorStat
	err := row.Scan(&i.TotalRegisteredValidators, &i.ActiveValidators, &i.DeregisteredValidators)
	return i, err
}

const getValidatorUptimeData = `-- name: GetValidatorUptimeData :many
SELECT 
    vsr.sla_id,
    vsr.blocks_proposed,
    vsr.challenges_received,
    vsr.challenges_failed,
    vr.block_quota,
    vr.start_block,
    vr.end_block,
    vr.tx,
    vr.date_finalized
FROM v_sla_rollup_score vsr
JOIN v_sla_rollup vr ON vsr.sla_id = vr.id
WHERE vsr.node = $1
ORDER BY vr.date_finalized DESC
LIMIT $2
`

type GetValidatorUptimeDataParams struct {
	Node  string `json:"node"`
	Limit int32  `json:"limit"`
}

type GetValidatorUptimeDataRow struct {
	SlaID              int32            `json:"sla_id"`
	BlocksProposed     int32            `json:"blocks_proposed"`
	ChallengesReceived int64            `json:"challenges_received"`
	ChallengesFailed   int32            `json:"challenges_failed"`
	BlockQuota         int32            `json:"block_quota"`
	StartBlock         int64            `json:"start_block"`
	EndBlock           int64            `json:"end_block"`
	Tx                 string           `json:"tx"`
	DateFinalized      pgtype.Timestamp `json:"date_finalized"`
}

// Get validator uptime data using SLA rollup views
func (q *Queries) GetValidatorUptimeData(ctx context.Context, arg GetValidatorUptimeDataParams) ([]GetValidatorUptimeDataRow, error) {
	rows, err := q.db.Query(ctx, getValidatorUptimeData, arg.Node, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorUptimeDataRow
	for rows.Next() {
		var i GetValidatorUptimeDataRow
		if err := rows.Scan(
			&i.SlaID,
			&i.BlocksProposed,
			&i.ChallengesReceived,
			&i.ChallengesFailed,
			&i.BlockQuota,
			&i.StartBlock,
			&i.EndBlock,
			&i.Tx,
			&i.DateFinalized,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchAddress = `-- name: SearchAddress :many
SELECT DISTINCT address
FROM etl_addresses
WHERE address ILIKE '%' || $1 || '%'
LIMIT 10
`

// Search addresses
func (q *Queries) SearchAddress(ctx context.Context, dollar_1 pgtype.Text) ([]string, error) {
	rows, err := q.db.Query(ctx, searchAddress, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var address string
		if err := rows.Scan(&address); err != nil {
			return nil, err
		}
		items = append(items, address)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchUnified = `-- name: SearchUnified :many
SELECT 
    'transaction' as type,
    t.tx_hash as id,
    'Transaction ' || SUBSTRING(t.tx_hash, 1, 8) || '...' as title,
    t.tx_type || ' at block ' || b.block_height as subtitle
FROM etl_transactions_v2 t
JOIN etl_blocks b ON t.block_id = b.id
WHERE t.tx_hash ILIKE '%' || $1 || '%'
UNION ALL
SELECT 
    'block' as type,
    b.block_height::text as id,
    'Block ' || b.block_height as title,
    'Proposed by ' || SUBSTRING(b.proposer_address, 1, 8) || '...' as subtitle
FROM etl_blocks b
WHERE b.block_height::text ILIKE '%' || $1 || '%'
UNION ALL
SELECT 
    'account' as type,
    a.address as id,
    SUBSTRING(a.address, 1, 8) || '...' as title,
    'Address' as subtitle
FROM etl_addresses a
WHERE a.address ILIKE '%' || $1 || '%'
ORDER BY type, id
LIMIT $2
`

type SearchUnifiedParams struct {
	Column1 pgtype.Text `json:"column_1"`
	Limit   int32       `json:"limit"`
}

type SearchUnifiedRow struct {
	Type     string      `json:"type"`
	ID       string      `json:"id"`
	Title    interface{} `json:"title"`
	Subtitle interface{} `json:"subtitle"`
}

// Search functionality using normalized schema
func (q *Queries) SearchUnified(ctx context.Context, arg SearchUnifiedParams) ([]SearchUnifiedRow, error) {
	rows, err := q.db.Query(ctx, searchUnified, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SearchUnifiedRow
	for rows.Next() {
		var i SearchUnifiedRow
		if err := rows.Scan(
			&i.Type,
			&i.ID,
			&i.Title,
			&i.Subtitle,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchValidatorRegistration = `-- name: SearchValidatorRegistration :many
SELECT DISTINCT a.address
FROM etl_validator_registrations_v2 vr
JOIN etl_addresses a ON vr.address_id = a.id
WHERE a.address ILIKE '%' || $1 || '%'
   OR vr.comet_address ILIKE '%' || $1 || '%'
   OR vr.endpoint ILIKE '%' || $1 || '%'
LIMIT 10
`

// Search validator registrations
func (q *Queries) SearchValidatorRegistration(ctx context.Context, dollar_1 pgtype.Text) ([]string, error) {
	rows, err := q.db.Query(ctx, searchValidatorRegistration, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var address string
		if err := rows.Scan(&address); err != nil {
			return nil, err
		}
		items = append(items, address)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
