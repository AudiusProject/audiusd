// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: reads.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const getActiveValidatorsCount = `-- name: GetActiveValidatorsCount :one

select count(distinct r.comet_address) as count
from etl_validator_registrations r
left join etl_validator_deregistrations d on r.comet_address = d.comet_address
where d.comet_address is null
`

// Dashboard Statistics Queries
func (q *Queries) GetActiveValidatorsCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getActiveValidatorsCount)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const getAvailableCities = `-- name: GetAvailableCities :many
select city,
    region,
    country,
    count(*) as play_count
from etl_plays
where city is not null
    and (
        nullif($1, '')::text is null
        or lower(country) = lower($1)
    )
    and (
        nullif($2, '')::text is null
        or lower(region) = lower($2)
    )
group by city,
    region,
    country
order by count(*) desc
limit $3
`

type GetAvailableCitiesParams struct {
	Column1 interface{} `json:"column_1"`
	Column2 interface{} `json:"column_2"`
	Limit   int32       `json:"limit"`
}

type GetAvailableCitiesRow struct {
	City      string `json:"city"`
	Region    string `json:"region"`
	Country   string `json:"country"`
	PlayCount int64  `json:"play_count"`
}

func (q *Queries) GetAvailableCities(ctx context.Context, arg GetAvailableCitiesParams) ([]GetAvailableCitiesRow, error) {
	rows, err := q.db.Query(ctx, getAvailableCities, arg.Column1, arg.Column2, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableCitiesRow
	for rows.Next() {
		var i GetAvailableCitiesRow
		if err := rows.Scan(
			&i.City,
			&i.Region,
			&i.Country,
			&i.PlayCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAvailableCountries = `-- name: GetAvailableCountries :many
select country,
    count(*) as play_count
from etl_plays
where country is not null
group by country
order by count(*) desc
limit $1
`

type GetAvailableCountriesRow struct {
	Country   string `json:"country"`
	PlayCount int64  `json:"play_count"`
}

func (q *Queries) GetAvailableCountries(ctx context.Context, limit int32) ([]GetAvailableCountriesRow, error) {
	rows, err := q.db.Query(ctx, getAvailableCountries, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableCountriesRow
	for rows.Next() {
		var i GetAvailableCountriesRow
		if err := rows.Scan(&i.Country, &i.PlayCount); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAvailableRegions = `-- name: GetAvailableRegions :many
select region,
    country,
    count(*) as play_count
from etl_plays
where region is not null
    and (
        nullif($1, '')::text is null
        or lower(country) = lower($1)
    )
group by region,
    country
order by count(*) desc
limit $2
`

type GetAvailableRegionsParams struct {
	Column1 interface{} `json:"column_1"`
	Limit   int32       `json:"limit"`
}

type GetAvailableRegionsRow struct {
	Region    string `json:"region"`
	Country   string `json:"country"`
	PlayCount int64  `json:"play_count"`
}

func (q *Queries) GetAvailableRegions(ctx context.Context, arg GetAvailableRegionsParams) ([]GetAvailableRegionsRow, error) {
	rows, err := q.db.Query(ctx, getAvailableRegions, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAvailableRegionsRow
	for rows.Next() {
		var i GetAvailableRegionsRow
		if err := rows.Scan(&i.Region, &i.Country, &i.PlayCount); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBlockRangeByTime = `-- name: GetBlockRangeByTime :one
select min(block_height) as start_block,
    max(block_height) as end_block
from etl_blocks
where block_time between $1 and $2
`

type GetBlockRangeByTimeParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

type GetBlockRangeByTimeRow struct {
	StartBlock interface{} `json:"start_block"`
	EndBlock   interface{} `json:"end_block"`
}

func (q *Queries) GetBlockRangeByTime(ctx context.Context, arg GetBlockRangeByTimeParams) (GetBlockRangeByTimeRow, error) {
	row := q.db.QueryRow(ctx, getBlockRangeByTime, arg.BlockTime, arg.BlockTime_2)
	var i GetBlockRangeByTimeRow
	err := row.Scan(&i.StartBlock, &i.EndBlock)
	return i, err
}

const getBlockTransactions = `-- name: GetBlockTransactions :many
select id, tx_hash, block_height, index, tx_type, created_at, updated_at from etl_transactions
where block_height = $1
`

func (q *Queries) GetBlockTransactions(ctx context.Context, blockHeight int64) ([]EtlTransaction, error) {
	rows, err := q.db.Query(ctx, getBlockTransactions, blockHeight)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlTransaction
	for rows.Next() {
		var i EtlTransaction
		if err := rows.Scan(
			&i.ID,
			&i.TxHash,
			&i.BlockHeight,
			&i.Index,
			&i.TxType,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBlocks = `-- name: GetBlocks :many
select id, proposer_address, block_height, block_time, created_at, updated_at from etl_blocks where block_height between $1 and $2 order by block_height desc
`

type GetBlocksParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

func (q *Queries) GetBlocks(ctx context.Context, arg GetBlocksParams) ([]EtlBlock, error) {
	rows, err := q.db.Query(ctx, getBlocks, arg.BlockHeight, arg.BlockHeight_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlBlock
	for rows.Next() {
		var i EtlBlock
		if err := rows.Scan(
			&i.ID,
			&i.ProposerAddress,
			&i.BlockHeight,
			&i.BlockTime,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBlocksPerSecond = `-- name: GetBlocksPerSecond :one
select case 
    when extract(epoch from (max(block_time) - min(block_time))) > 0 
    then (count(*) - 1)::float / extract(epoch from (max(block_time) - min(block_time)))
    else 0.0
end as bps
from etl_blocks
where block_time >= now() - interval '1 hour'
`

func (q *Queries) GetBlocksPerSecond(ctx context.Context) (float64, error) {
	row := q.db.QueryRow(ctx, getBlocksPerSecond)
	var bps float64
	err := row.Scan(&bps)
	return bps, err
}

const getIndexedBlock = `-- name: GetIndexedBlock :one
select id, proposer_address, block_height, block_time, created_at, updated_at
from etl_blocks
where block_height = $1
`

func (q *Queries) GetIndexedBlock(ctx context.Context, blockHeight int64) (EtlBlock, error) {
	row := q.db.QueryRow(ctx, getIndexedBlock, blockHeight)
	var i EtlBlock
	err := row.Scan(
		&i.ID,
		&i.ProposerAddress,
		&i.BlockHeight,
		&i.BlockTime,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getLatestBlocks = `-- name: GetLatestBlocks :many
select id, proposer_address, block_height, block_time, created_at, updated_at
from etl_blocks
order by block_height desc
limit $1 offset $2
`

type GetLatestBlocksParams struct {
	Limit  int32 `json:"limit"`
	Offset int32 `json:"offset"`
}

func (q *Queries) GetLatestBlocks(ctx context.Context, arg GetLatestBlocksParams) ([]EtlBlock, error) {
	rows, err := q.db.Query(ctx, getLatestBlocks, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlBlock
	for rows.Next() {
		var i EtlBlock
		if err := rows.Scan(
			&i.ID,
			&i.ProposerAddress,
			&i.BlockHeight,
			&i.BlockTime,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getLatestIndexedBlock = `-- name: GetLatestIndexedBlock :one
select block_height
from etl_blocks
order by id desc
limit 1
`

// get latest indexed block height
func (q *Queries) GetLatestIndexedBlock(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getLatestIndexedBlock)
	var block_height int64
	err := row.Scan(&block_height)
	return block_height, err
}

const getLatestSLARollup = `-- name: GetLatestSLARollup :one
select id, timestamp, block_start, block_end, block_height, tx_hash, created_at, updated_at from etl_sla_rollups order by block_height desc limit 1
`

func (q *Queries) GetLatestSLARollup(ctx context.Context) (EtlSlaRollup, error) {
	row := q.db.QueryRow(ctx, getLatestSLARollup)
	var i EtlSlaRollup
	err := row.Scan(
		&i.ID,
		&i.Timestamp,
		&i.BlockStart,
		&i.BlockEnd,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getLatestTransactions = `-- name: GetLatestTransactions :many
select t.id, t.tx_hash, t.block_height, t.index, t.tx_type, t.created_at, t.updated_at, b.block_time
from etl_transactions t
join etl_blocks b on t.block_height = b.block_height
order by t.id desc
limit $1 offset $2
`

type GetLatestTransactionsParams struct {
	Limit  int32 `json:"limit"`
	Offset int32 `json:"offset"`
}

type GetLatestTransactionsRow struct {
	ID          int32            `json:"id"`
	TxHash      string           `json:"tx_hash"`
	BlockHeight int64            `json:"block_height"`
	Index       int64            `json:"index"`
	TxType      string           `json:"tx_type"`
	CreatedAt   pgtype.Timestamp `json:"created_at"`
	UpdatedAt   pgtype.Timestamp `json:"updated_at"`
	BlockTime   pgtype.Timestamp `json:"block_time"`
}

func (q *Queries) GetLatestTransactions(ctx context.Context, arg GetLatestTransactionsParams) ([]GetLatestTransactionsRow, error) {
	rows, err := q.db.Query(ctx, getLatestTransactions, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetLatestTransactionsRow
	for rows.Next() {
		var i GetLatestTransactionsRow
		if err := rows.Scan(
			&i.ID,
			&i.TxHash,
			&i.BlockHeight,
			&i.Index,
			&i.TxType,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.BlockTime,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getManageEntitiesByTxHash = `-- name: GetManageEntitiesByTxHash :many
select address,
    entity_type,
    entity_id,
    action,
    metadata,
    signature,
    signer,
    nonce,
    block_height,
    tx_hash
from etl_manage_entities
where tx_hash = $1
`

type GetManageEntitiesByTxHashRow struct {
	Address     string      `json:"address"`
	EntityType  string      `json:"entity_type"`
	EntityID    int64       `json:"entity_id"`
	Action      string      `json:"action"`
	Metadata    pgtype.Text `json:"metadata"`
	Signature   string      `json:"signature"`
	Signer      string      `json:"signer"`
	Nonce       string      `json:"nonce"`
	BlockHeight int64       `json:"block_height"`
	TxHash      string      `json:"tx_hash"`
}

func (q *Queries) GetManageEntitiesByTxHash(ctx context.Context, txHash string) ([]GetManageEntitiesByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getManageEntitiesByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetManageEntitiesByTxHashRow
	for rows.Next() {
		var i GetManageEntitiesByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.EntityType,
			&i.EntityID,
			&i.Action,
			&i.Metadata,
			&i.Signature,
			&i.Signer,
			&i.Nonce,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlayCountByAddress = `-- name: GetPlayCountByAddress :one
select count(*) as play_count
from etl_plays
where address = $1
`

// get play count by address
func (q *Queries) GetPlayCountByAddress(ctx context.Context, address string) (int64, error) {
	row := q.db.QueryRow(ctx, getPlayCountByAddress, address)
	var play_count int64
	err := row.Scan(&play_count)
	return play_count, err
}

const getPlayCountByTrack = `-- name: GetPlayCountByTrack :one
select count(*) as play_count
from etl_plays
where track_id = $1
`

// get play count by track
func (q *Queries) GetPlayCountByTrack(ctx context.Context, trackID string) (int64, error) {
	row := q.db.QueryRow(ctx, getPlayCountByTrack, trackID)
	var play_count int64
	err := row.Scan(&play_count)
	return play_count, err
}

const getPlays = `-- name: GetPlays :many
select address,
    track_id,
    extract(
        epoch
        from played_at
    )::bigint as timestamp,
    city,
    country,
    region,
    block_height,
    tx_hash
from etl_plays
where block_height between $1 and $2
order by played_at desc
limit $3 offset $4
`

type GetPlaysParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
	Limit         int32 `json:"limit"`
	Offset        int32 `json:"offset"`
}

type GetPlaysRow struct {
	Address     string `json:"address"`
	TrackID     string `json:"track_id"`
	Timestamp   int64  `json:"timestamp"`
	City        string `json:"city"`
	Country     string `json:"country"`
	Region      string `json:"region"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetPlays(ctx context.Context, arg GetPlaysParams) ([]GetPlaysRow, error) {
	rows, err := q.db.Query(ctx, getPlays,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysRow
	for rows.Next() {
		var i GetPlaysRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByAddress = `-- name: GetPlaysByAddress :many
select address,
    track_id,
    extract(
        epoch
        from played_at
    )::bigint as timestamp,
    city,
    country,
    region,
    block_height,
    tx_hash
from etl_plays
where address = $1
    and block_height between $2 and $3
order by played_at desc
limit $4 offset $5
`

type GetPlaysByAddressParams struct {
	Address       string `json:"address"`
	BlockHeight   int64  `json:"block_height"`
	BlockHeight_2 int64  `json:"block_height_2"`
	Limit         int32  `json:"limit"`
	Offset        int32  `json:"offset"`
}

type GetPlaysByAddressRow struct {
	Address     string `json:"address"`
	TrackID     string `json:"track_id"`
	Timestamp   int64  `json:"timestamp"`
	City        string `json:"city"`
	Country     string `json:"country"`
	Region      string `json:"region"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetPlaysByAddress(ctx context.Context, arg GetPlaysByAddressParams) ([]GetPlaysByAddressRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByAddress,
		arg.Address,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByAddressRow
	for rows.Next() {
		var i GetPlaysByAddressRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByLocation = `-- name: GetPlaysByLocation :many
select tx_hash,
    address,
    track_id,
    played_at,
    city,
    region,
    country,
    created_at
from etl_plays
where (
        nullif($1, '')::text is null
        or lower(city) = lower($1)
    )
    and (
        nullif($2, '')::text is null
        or lower(region) = lower($2)
    )
    and (
        nullif($3, '')::text is null
        or lower(country) = lower($3)
    )
order by played_at desc
limit $4
`

type GetPlaysByLocationParams struct {
	Column1 interface{} `json:"column_1"`
	Column2 interface{} `json:"column_2"`
	Column3 interface{} `json:"column_3"`
	Limit   int32       `json:"limit"`
}

type GetPlaysByLocationRow struct {
	TxHash    string           `json:"tx_hash"`
	Address   string           `json:"address"`
	TrackID   string           `json:"track_id"`
	PlayedAt  pgtype.Timestamp `json:"played_at"`
	City      string           `json:"city"`
	Region    string           `json:"region"`
	Country   string           `json:"country"`
	CreatedAt pgtype.Timestamp `json:"created_at"`
}

func (q *Queries) GetPlaysByLocation(ctx context.Context, arg GetPlaysByLocationParams) ([]GetPlaysByLocationRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByLocation,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByLocationRow
	for rows.Next() {
		var i GetPlaysByLocationRow
		if err := rows.Scan(
			&i.TxHash,
			&i.Address,
			&i.TrackID,
			&i.PlayedAt,
			&i.City,
			&i.Region,
			&i.Country,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByTrack = `-- name: GetPlaysByTrack :many
select address,
    track_id,
    extract(
        epoch
        from played_at
    )::bigint as timestamp,
    city,
    country,
    region,
    block_height,
    tx_hash
from etl_plays
where track_id = $1
    and block_height between $2 and $3
order by played_at desc
limit $4 offset $5
`

type GetPlaysByTrackParams struct {
	TrackID       string `json:"track_id"`
	BlockHeight   int64  `json:"block_height"`
	BlockHeight_2 int64  `json:"block_height_2"`
	Limit         int32  `json:"limit"`
	Offset        int32  `json:"offset"`
}

type GetPlaysByTrackRow struct {
	Address     string `json:"address"`
	TrackID     string `json:"track_id"`
	Timestamp   int64  `json:"timestamp"`
	City        string `json:"city"`
	Country     string `json:"country"`
	Region      string `json:"region"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetPlaysByTrack(ctx context.Context, arg GetPlaysByTrackParams) ([]GetPlaysByTrackRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByTrack,
		arg.TrackID,
		arg.BlockHeight,
		arg.BlockHeight_2,
		arg.Limit,
		arg.Offset,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByTrackRow
	for rows.Next() {
		var i GetPlaysByTrackRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysByTxHash = `-- name: GetPlaysByTxHash :many
select address,
    track_id,
    extract(
        epoch
        from played_at
    )::bigint as timestamp,
    city,
    country,
    region,
    block_height,
    tx_hash
from etl_plays
where tx_hash = $1
`

type GetPlaysByTxHashRow struct {
	Address     string `json:"address"`
	TrackID     string `json:"track_id"`
	Timestamp   int64  `json:"timestamp"`
	City        string `json:"city"`
	Country     string `json:"country"`
	Region      string `json:"region"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetPlaysByTxHash(ctx context.Context, txHash string) ([]GetPlaysByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getPlaysByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPlaysByTxHashRow
	for rows.Next() {
		var i GetPlaysByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.TrackID,
			&i.Timestamp,
			&i.City,
			&i.Country,
			&i.Region,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlaysCount = `-- name: GetPlaysCount :one
select count(*) as total
from etl_plays
where (
        $1::text is null
        or address = $1
    )
    and (
        $2::text is null
        or track_id = $2
    )
    and (
        $3::timestamp is null
        or $4::timestamp is null
        or played_at between $3 and $4
    )
`

type GetPlaysCountParams struct {
	Column1 string           `json:"column_1"`
	Column2 string           `json:"column_2"`
	Column3 pgtype.Timestamp `json:"column_3"`
	Column4 pgtype.Timestamp `json:"column_4"`
}

// get total count of plays with filtering
func (q *Queries) GetPlaysCount(ctx context.Context, arg GetPlaysCountParams) (int64, error) {
	row := q.db.QueryRow(ctx, getPlaysCount,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
	)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getRecentProposers = `-- name: GetRecentProposers :many
select distinct proposer_address
from etl_blocks
order by block_height desc
limit $1
`

func (q *Queries) GetRecentProposers(ctx context.Context, limit int32) ([]string, error) {
	rows, err := q.db.Query(ctx, getRecentProposers, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var proposer_address string
		if err := rows.Scan(&proposer_address); err != nil {
			return nil, err
		}
		items = append(items, proposer_address)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getReleasesByTxHash = `-- name: GetReleasesByTxHash :many
select release_data,
    block_height,
    tx_hash
from etl_releases
where tx_hash = $1
`

type GetReleasesByTxHashRow struct {
	ReleaseData []byte `json:"release_data"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetReleasesByTxHash(ctx context.Context, txHash string) ([]GetReleasesByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getReleasesByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetReleasesByTxHashRow
	for rows.Next() {
		var i GetReleasesByTxHashRow
		if err := rows.Scan(&i.ReleaseData, &i.BlockHeight, &i.TxHash); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSlaNodeReportsByTxHash = `-- name: GetSlaNodeReportsByTxHash :many
select sla_rollup_id,
    address,
    num_blocks_proposed,
    block_height,
    tx_hash
from etl_sla_node_reports
where tx_hash = $1
`

type GetSlaNodeReportsByTxHashRow struct {
	SlaRollupID       int32  `json:"sla_rollup_id"`
	Address           string `json:"address"`
	NumBlocksProposed int32  `json:"num_blocks_proposed"`
	BlockHeight       int64  `json:"block_height"`
	TxHash            string `json:"tx_hash"`
}

func (q *Queries) GetSlaNodeReportsByTxHash(ctx context.Context, txHash string) ([]GetSlaNodeReportsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getSlaNodeReportsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetSlaNodeReportsByTxHashRow
	for rows.Next() {
		var i GetSlaNodeReportsByTxHashRow
		if err := rows.Scan(
			&i.SlaRollupID,
			&i.Address,
			&i.NumBlocksProposed,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSlaRollupsByTxHash = `-- name: GetSlaRollupsByTxHash :many
select block_start,
    block_end,
    timestamp,
    block_height,
    tx_hash
from etl_sla_rollups
where tx_hash = $1
`

type GetSlaRollupsByTxHashRow struct {
	BlockStart  int64            `json:"block_start"`
	BlockEnd    int64            `json:"block_end"`
	Timestamp   pgtype.Timestamp `json:"timestamp"`
	BlockHeight int64            `json:"block_height"`
	TxHash      string           `json:"tx_hash"`
}

func (q *Queries) GetSlaRollupsByTxHash(ctx context.Context, txHash string) ([]GetSlaRollupsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getSlaRollupsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetSlaRollupsByTxHashRow
	for rows.Next() {
		var i GetSlaRollupsByTxHashRow
		if err := rows.Scan(
			&i.BlockStart,
			&i.BlockEnd,
			&i.Timestamp,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStorageProofVerificationsByTxHash = `-- name: GetStorageProofVerificationsByTxHash :many
select height,
    proof,
    block_height,
    tx_hash
from etl_storage_proof_verifications
where tx_hash = $1
`

type GetStorageProofVerificationsByTxHashRow struct {
	Height      int64  `json:"height"`
	Proof       []byte `json:"proof"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

func (q *Queries) GetStorageProofVerificationsByTxHash(ctx context.Context, txHash string) ([]GetStorageProofVerificationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getStorageProofVerificationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetStorageProofVerificationsByTxHashRow
	for rows.Next() {
		var i GetStorageProofVerificationsByTxHashRow
		if err := rows.Scan(
			&i.Height,
			&i.Proof,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStorageProofsByTxHash = `-- name: GetStorageProofsByTxHash :many
select address,
    height,
    prover_addresses,
    cid,
    proof_signature,
    block_height,
    tx_hash
from etl_storage_proofs
where tx_hash = $1
`

type GetStorageProofsByTxHashRow struct {
	Address         string   `json:"address"`
	Height          int64    `json:"height"`
	ProverAddresses []string `json:"prover_addresses"`
	Cid             string   `json:"cid"`
	ProofSignature  []byte   `json:"proof_signature"`
	BlockHeight     int64    `json:"block_height"`
	TxHash          string   `json:"tx_hash"`
}

func (q *Queries) GetStorageProofsByTxHash(ctx context.Context, txHash string) ([]GetStorageProofsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getStorageProofsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetStorageProofsByTxHashRow
	for rows.Next() {
		var i GetStorageProofsByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.Height,
			&i.ProverAddresses,
			&i.Cid,
			&i.ProofSignature,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTotalBlocksCount = `-- name: GetTotalBlocksCount :one
select count(*) as total
from etl_blocks
`

func (q *Queries) GetTotalBlocksCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getTotalBlocksCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTotalTransactionsCount = `-- name: GetTotalTransactionsCount :one
select count(*) as total
from etl_transactions
`

func (q *Queries) GetTotalTransactionsCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getTotalTransactionsCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTransaction = `-- name: GetTransaction :one
select t.id, t.tx_hash, t.block_height, t.index, t.tx_type, t.created_at, t.updated_at, b.block_time, b.proposer_address
from etl_transactions t
join etl_blocks b on t.block_height = b.block_height
where t.tx_hash = $1
`

type GetTransactionRow struct {
	ID              int32            `json:"id"`
	TxHash          string           `json:"tx_hash"`
	BlockHeight     int64            `json:"block_height"`
	Index           int64            `json:"index"`
	TxType          string           `json:"tx_type"`
	CreatedAt       pgtype.Timestamp `json:"created_at"`
	UpdatedAt       pgtype.Timestamp `json:"updated_at"`
	BlockTime       pgtype.Timestamp `json:"block_time"`
	ProposerAddress string           `json:"proposer_address"`
}

func (q *Queries) GetTransaction(ctx context.Context, txHash string) (GetTransactionRow, error) {
	row := q.db.QueryRow(ctx, getTransaction, txHash)
	var i GetTransactionRow
	err := row.Scan(
		&i.ID,
		&i.TxHash,
		&i.BlockHeight,
		&i.Index,
		&i.TxType,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.BlockTime,
		&i.ProposerAddress,
	)
	return i, err
}

const getTransactionTypeBreakdown = `-- name: GetTransactionTypeBreakdown :many
select tx_type as type,
    count(*) as count
from etl_transactions t
join etl_blocks b on t.block_height = b.block_height
where b.block_time >= now() - interval '24 hours'
group by tx_type
order by count(*) desc
`

type GetTransactionTypeBreakdownRow struct {
	Type  string `json:"type"`
	Count int64  `json:"count"`
}

func (q *Queries) GetTransactionTypeBreakdown(ctx context.Context) ([]GetTransactionTypeBreakdownRow, error) {
	rows, err := q.db.Query(ctx, getTransactionTypeBreakdown)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetTransactionTypeBreakdownRow
	for rows.Next() {
		var i GetTransactionTypeBreakdownRow
		if err := rows.Scan(&i.Type, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTransactionsCount = `-- name: GetTransactionsCount :one
select count(*) from etl_transactions where block_height between $1 and $2
`

type GetTransactionsCountParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

func (q *Queries) GetTransactionsCount(ctx context.Context, arg GetTransactionsCountParams) (int64, error) {
	row := q.db.QueryRow(ctx, getTransactionsCount, arg.BlockHeight, arg.BlockHeight_2)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const getTransactionsCountTimeRange = `-- name: GetTransactionsCountTimeRange :one
select count(*) as total
from etl_transactions t
join etl_blocks b on t.block_height = b.block_height
where b.block_time between $1 and $2
`

type GetTransactionsCountTimeRangeParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

func (q *Queries) GetTransactionsCountTimeRange(ctx context.Context, arg GetTransactionsCountTimeRangeParams) (int64, error) {
	row := q.db.QueryRow(ctx, getTransactionsCountTimeRange, arg.BlockTime, arg.BlockTime_2)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTransactionsCountTimeRangeSubquery = `-- name: GetTransactionsCountTimeRangeSubquery :one
select count(*) as total
from etl_transactions
where block_height in (
    select block_height 
    from etl_blocks 
    where block_time between $1 and $2
)
`

type GetTransactionsCountTimeRangeSubqueryParams struct {
	BlockTime   pgtype.Timestamp `json:"block_time"`
	BlockTime_2 pgtype.Timestamp `json:"block_time_2"`
}

// Alternative subquery approach for transaction count by time range
func (q *Queries) GetTransactionsCountTimeRangeSubquery(ctx context.Context, arg GetTransactionsCountTimeRangeSubqueryParams) (int64, error) {
	row := q.db.QueryRow(ctx, getTransactionsCountTimeRangeSubquery, arg.BlockTime, arg.BlockTime_2)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getTransactionsPerSecond = `-- name: GetTransactionsPerSecond :one
select case 
    when extract(epoch from (max(b.block_time) - min(b.block_time))) > 0 
    then count(t.*)::float / extract(epoch from (max(b.block_time) - min(b.block_time)))
    else 0.0
end as tps
from etl_transactions t
join etl_blocks b on t.block_height = b.block_height
where b.block_time >= now() - interval '1 hour'
`

func (q *Queries) GetTransactionsPerSecond(ctx context.Context) (float64, error) {
	row := q.db.QueryRow(ctx, getTransactionsPerSecond)
	var tps float64
	err := row.Scan(&tps)
	return tps, err
}

const getValidatorDeregistrations = `-- name: GetValidatorDeregistrations :many
select comet_address,
    comet_pubkey,
    block_height,
    tx_hash
from etl_validator_deregistrations
`

type GetValidatorDeregistrationsRow struct {
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// get validator deregistrations
func (q *Queries) GetValidatorDeregistrations(ctx context.Context) ([]GetValidatorDeregistrationsRow, error) {
	rows, err := q.db.Query(ctx, getValidatorDeregistrations)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorDeregistrationsRow
	for rows.Next() {
		var i GetValidatorDeregistrationsRow
		if err := rows.Scan(
			&i.CometAddress,
			&i.CometPubkey,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorDeregistrationsByTxHash = `-- name: GetValidatorDeregistrationsByTxHash :many
select comet_address,
    comet_pubkey,
    block_height,
    tx_hash
from etl_validator_deregistrations
where tx_hash = $1
`

type GetValidatorDeregistrationsByTxHashRow struct {
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

func (q *Queries) GetValidatorDeregistrationsByTxHash(ctx context.Context, txHash string) ([]GetValidatorDeregistrationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getValidatorDeregistrationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorDeregistrationsByTxHashRow
	for rows.Next() {
		var i GetValidatorDeregistrationsByTxHashRow
		if err := rows.Scan(
			&i.CometAddress,
			&i.CometPubkey,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorRegistrations = `-- name: GetValidatorRegistrations :many
select distinct on (address) address,
    endpoint,
    comet_address,
    comet_pubkey,
    eth_block,
    node_type,
    spid,
    voting_power,
    block_height,
    tx_hash
from etl_validator_registrations
order by address, block_height desc
`

type GetValidatorRegistrationsRow struct {
	Address      string `json:"address"`
	Endpoint     string `json:"endpoint"`
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	Spid         string `json:"spid"`
	VotingPower  int64  `json:"voting_power"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// get validator registrations (deduplicated by address, keeping latest)
func (q *Queries) GetValidatorRegistrations(ctx context.Context) ([]GetValidatorRegistrationsRow, error) {
	rows, err := q.db.Query(ctx, getValidatorRegistrations)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorRegistrationsRow
	for rows.Next() {
		var i GetValidatorRegistrationsRow
		if err := rows.Scan(
			&i.Address,
			&i.Endpoint,
			&i.CometAddress,
			&i.CometPubkey,
			&i.EthBlock,
			&i.NodeType,
			&i.Spid,
			&i.VotingPower,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getValidatorRegistrationsByTxHash = `-- name: GetValidatorRegistrationsByTxHash :many
select address,
    comet_address,
    comet_pubkey,
    eth_block,
    node_type,
    spid,
    voting_power,
    block_height,
    tx_hash
from etl_validator_registrations
where tx_hash = $1
`

type GetValidatorRegistrationsByTxHashRow struct {
	Address      string `json:"address"`
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	Spid         string `json:"spid"`
	VotingPower  int64  `json:"voting_power"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

func (q *Queries) GetValidatorRegistrationsByTxHash(ctx context.Context, txHash string) ([]GetValidatorRegistrationsByTxHashRow, error) {
	rows, err := q.db.Query(ctx, getValidatorRegistrationsByTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetValidatorRegistrationsByTxHashRow
	for rows.Next() {
		var i GetValidatorRegistrationsByTxHashRow
		if err := rows.Scan(
			&i.Address,
			&i.CometAddress,
			&i.CometPubkey,
			&i.EthBlock,
			&i.NodeType,
			&i.Spid,
			&i.VotingPower,
			&i.BlockHeight,
			&i.TxHash,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchAddress = `-- name: SearchAddress :many
select address
from etl_manage_entities
where address % $1
    and similarity(address, $1) > 0.4
    and address like $1 || '%'
order by similarity(address, $1) desc
`

func (q *Queries) SearchAddress(ctx context.Context, address string) ([]string, error) {
	rows, err := q.db.Query(ctx, searchAddress, address)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var address string
		if err := rows.Scan(&address); err != nil {
			return nil, err
		}
		items = append(items, address)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchBlockHeight = `-- name: SearchBlockHeight :many
select block_height
from etl_blocks
where block_height::text % $1
    and similarity(block_height::text, $1) > 0.4
    and block_height::text like $1 || '%'
order by similarity(block_height::text, $1) desc
`

func (q *Queries) SearchBlockHeight(ctx context.Context, blockHeight int64) ([]int64, error) {
	rows, err := q.db.Query(ctx, searchBlockHeight, blockHeight)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []int64
	for rows.Next() {
		var block_height int64
		if err := rows.Scan(&block_height); err != nil {
			return nil, err
		}
		items = append(items, block_height)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchTxHash = `-- name: SearchTxHash :many
select tx_hash
from etl_transactions
where tx_hash % $1
    and similarity(tx_hash, $1) > 0.4
    and tx_hash like $1 || '%'
order by similarity(tx_hash, $1) desc
`

func (q *Queries) SearchTxHash(ctx context.Context, txHash string) ([]string, error) {
	rows, err := q.db.Query(ctx, searchTxHash, txHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var tx_hash string
		if err := rows.Scan(&tx_hash); err != nil {
			return nil, err
		}
		items = append(items, tx_hash)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchValidatorRegistration = `-- name: SearchValidatorRegistration :many
select address
from etl_validator_registrations
where address % $1
    and similarity(address, $1) > 0.4
    and address like $1 || '%'
order by similarity(address, $1) desc
`

func (q *Queries) SearchValidatorRegistration(ctx context.Context, address string) ([]string, error) {
	rows, err := q.db.Query(ctx, searchValidatorRegistration, address)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []string
	for rows.Next() {
		var address string
		if err := rows.Scan(&address); err != nil {
			return nil, err
		}
		items = append(items, address)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
