// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: writes.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const deleteManageEntitiesByBlockRange = `-- name: DeleteManageEntitiesByBlockRange :exec
delete from etl_manage_entities
where block_height between $1 and $2
`

type DeleteManageEntitiesByBlockRangeParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

// delete manage entities by block height range (useful for reindexing)
func (q *Queries) DeleteManageEntitiesByBlockRange(ctx context.Context, arg DeleteManageEntitiesByBlockRangeParams) error {
	_, err := q.db.Exec(ctx, deleteManageEntitiesByBlockRange, arg.BlockHeight, arg.BlockHeight_2)
	return err
}

const deletePlaysByBlockRange = `-- name: DeletePlaysByBlockRange :exec
delete from etl_plays
where block_height between $1 and $2
`

type DeletePlaysByBlockRangeParams struct {
	BlockHeight   int64 `json:"block_height"`
	BlockHeight_2 int64 `json:"block_height_2"`
}

// delete plays by block height range (useful for reindexing)
func (q *Queries) DeletePlaysByBlockRange(ctx context.Context, arg DeletePlaysByBlockRangeParams) error {
	_, err := q.db.Exec(ctx, deletePlaysByBlockRange, arg.BlockHeight, arg.BlockHeight_2)
	return err
}

const insertBlock = `-- name: InsertBlock :one
insert into etl_blocks (
        proposer_address,
        block_height,
        block_time
    )
values ($1, $2, $3)
returning id, proposer_address, block_height, block_time, created_at, updated_at
`

type InsertBlockParams struct {
	ProposerAddress string           `json:"proposer_address"`
	BlockHeight     int64            `json:"block_height"`
	BlockTime       pgtype.Timestamp `json:"block_time"`
}

// insert a new block record
func (q *Queries) InsertBlock(ctx context.Context, arg InsertBlockParams) (EtlBlock, error) {
	row := q.db.QueryRow(ctx, insertBlock, arg.ProposerAddress, arg.BlockHeight, arg.BlockTime)
	var i EtlBlock
	err := row.Scan(
		&i.ID,
		&i.ProposerAddress,
		&i.BlockHeight,
		&i.BlockTime,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertManageEntities = `-- name: InsertManageEntities :many
insert into etl_manage_entities (
        address,
        entity_type,
        entity_id,
        action,
        metadata,
        signature,
        signer,
        nonce,
        block_height,
        tx_hash
    )
values (
        unnest($1::text []),
        unnest($2::text []),
        unnest($3::bigint []),
        unnest($4::text []),
        unnest($5::text []),
        unnest($6::text []),
        unnest($7::text []),
        unnest($8::text []),
        unnest($9::bigint []),
        unnest($10::text [])
    ) on conflict do nothing
returning id, address, entity_type, entity_id, action, metadata, signature, signer, nonce, block_height, tx_hash, created_at, updated_at
`

type InsertManageEntitiesParams struct {
	Column1  []string `json:"column_1"`
	Column2  []string `json:"column_2"`
	Column3  []int64  `json:"column_3"`
	Column4  []string `json:"column_4"`
	Column5  []string `json:"column_5"`
	Column6  []string `json:"column_6"`
	Column7  []string `json:"column_7"`
	Column8  []string `json:"column_8"`
	Column9  []int64  `json:"column_9"`
	Column10 []string `json:"column_10"`
}

// insert multiple manage entity records with batch size control
func (q *Queries) InsertManageEntities(ctx context.Context, arg InsertManageEntitiesParams) ([]EtlManageEntity, error) {
	rows, err := q.db.Query(ctx, insertManageEntities,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
		arg.Column5,
		arg.Column6,
		arg.Column7,
		arg.Column8,
		arg.Column9,
		arg.Column10,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlManageEntity
	for rows.Next() {
		var i EtlManageEntity
		if err := rows.Scan(
			&i.ID,
			&i.Address,
			&i.EntityType,
			&i.EntityID,
			&i.Action,
			&i.Metadata,
			&i.Signature,
			&i.Signer,
			&i.Nonce,
			&i.BlockHeight,
			&i.TxHash,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const insertManageEntity = `-- name: InsertManageEntity :one
insert into etl_manage_entities (
        address,
        entity_type,
        entity_id,
        action,
        metadata,
        signature,
        signer,
        nonce,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
returning id, address, entity_type, entity_id, action, metadata, signature, signer, nonce, block_height, tx_hash, created_at, updated_at
`

type InsertManageEntityParams struct {
	Address     string      `json:"address"`
	EntityType  string      `json:"entity_type"`
	EntityID    int64       `json:"entity_id"`
	Action      string      `json:"action"`
	Metadata    pgtype.Text `json:"metadata"`
	Signature   string      `json:"signature"`
	Signer      string      `json:"signer"`
	Nonce       string      `json:"nonce"`
	BlockHeight int64       `json:"block_height"`
	TxHash      string      `json:"tx_hash"`
}

// insert a new manage entity record
func (q *Queries) InsertManageEntity(ctx context.Context, arg InsertManageEntityParams) (EtlManageEntity, error) {
	row := q.db.QueryRow(ctx, insertManageEntity,
		arg.Address,
		arg.EntityType,
		arg.EntityID,
		arg.Action,
		arg.Metadata,
		arg.Signature,
		arg.Signer,
		arg.Nonce,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlManageEntity
	err := row.Scan(
		&i.ID,
		&i.Address,
		&i.EntityType,
		&i.EntityID,
		&i.Action,
		&i.Metadata,
		&i.Signature,
		&i.Signer,
		&i.Nonce,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertPlay = `-- name: InsertPlay :one
insert into etl_plays (
        address,
        track_id,
        city,
        region,
        country,
        played_at,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5, $6, $7, $8)
returning id, address, track_id, city, region, country, played_at, block_height, tx_hash, created_at, updated_at
`

type InsertPlayParams struct {
	Address     string           `json:"address"`
	TrackID     string           `json:"track_id"`
	City        string           `json:"city"`
	Region      string           `json:"region"`
	Country     string           `json:"country"`
	PlayedAt    pgtype.Timestamp `json:"played_at"`
	BlockHeight int64            `json:"block_height"`
	TxHash      string           `json:"tx_hash"`
}

// insert a new play record
func (q *Queries) InsertPlay(ctx context.Context, arg InsertPlayParams) (EtlPlay, error) {
	row := q.db.QueryRow(ctx, insertPlay,
		arg.Address,
		arg.TrackID,
		arg.City,
		arg.Region,
		arg.Country,
		arg.PlayedAt,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlPlay
	err := row.Scan(
		&i.ID,
		&i.Address,
		&i.TrackID,
		&i.City,
		&i.Region,
		&i.Country,
		&i.PlayedAt,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertPlays = `-- name: InsertPlays :many
insert into etl_plays (
        address,
        track_id,
        city,
        region,
        country,
        played_at,
        block_height,
        tx_hash
    )
values (
        unnest($1::text []),
        unnest($2::text []),
        unnest($3::text []),
        unnest($4::text []),
        unnest($5::text []),
        unnest($6::timestamp []),
        unnest($7::bigint []),
        unnest($8::text [])
    ) on conflict do nothing
returning id, address, track_id, city, region, country, played_at, block_height, tx_hash, created_at, updated_at
`

type InsertPlaysParams struct {
	Column1 []string           `json:"column_1"`
	Column2 []string           `json:"column_2"`
	Column3 []string           `json:"column_3"`
	Column4 []string           `json:"column_4"`
	Column5 []string           `json:"column_5"`
	Column6 []pgtype.Timestamp `json:"column_6"`
	Column7 []int64            `json:"column_7"`
	Column8 []string           `json:"column_8"`
}

// insert multiple play records with batch size control
func (q *Queries) InsertPlays(ctx context.Context, arg InsertPlaysParams) ([]EtlPlay, error) {
	rows, err := q.db.Query(ctx, insertPlays,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
		arg.Column5,
		arg.Column6,
		arg.Column7,
		arg.Column8,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EtlPlay
	for rows.Next() {
		var i EtlPlay
		if err := rows.Scan(
			&i.ID,
			&i.Address,
			&i.TrackID,
			&i.City,
			&i.Region,
			&i.Country,
			&i.PlayedAt,
			&i.BlockHeight,
			&i.TxHash,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const insertRelease = `-- name: InsertRelease :one
insert into etl_releases (
        release_data,
        block_height,
        tx_hash
    )
values ($1, $2, $3)
returning id, release_data, block_height, tx_hash, created_at, updated_at
`

type InsertReleaseParams struct {
	ReleaseData []byte `json:"release_data"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

// insert a new release record
func (q *Queries) InsertRelease(ctx context.Context, arg InsertReleaseParams) (EtlRelease, error) {
	row := q.db.QueryRow(ctx, insertRelease, arg.ReleaseData, arg.BlockHeight, arg.TxHash)
	var i EtlRelease
	err := row.Scan(
		&i.ID,
		&i.ReleaseData,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertSlaNodeReport = `-- name: InsertSlaNodeReport :one
insert into etl_sla_node_reports (
        sla_rollup_id,
        address,
        num_blocks_proposed,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5)
returning id, sla_rollup_id, address, num_blocks_proposed, block_height, tx_hash, created_at, updated_at
`

type InsertSlaNodeReportParams struct {
	SlaRollupID       int32  `json:"sla_rollup_id"`
	Address           string `json:"address"`
	NumBlocksProposed int32  `json:"num_blocks_proposed"`
	BlockHeight       int64  `json:"block_height"`
	TxHash            string `json:"tx_hash"`
}

// insert a new SLA node report record
func (q *Queries) InsertSlaNodeReport(ctx context.Context, arg InsertSlaNodeReportParams) (EtlSlaNodeReport, error) {
	row := q.db.QueryRow(ctx, insertSlaNodeReport,
		arg.SlaRollupID,
		arg.Address,
		arg.NumBlocksProposed,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlSlaNodeReport
	err := row.Scan(
		&i.ID,
		&i.SlaRollupID,
		&i.Address,
		&i.NumBlocksProposed,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertSlaRollup = `-- name: InsertSlaRollup :one
insert into etl_sla_rollups (
        timestamp,
        block_start,
        block_end,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5)
returning id, timestamp, block_start, block_end, block_height, tx_hash, created_at, updated_at
`

type InsertSlaRollupParams struct {
	Timestamp   pgtype.Timestamp `json:"timestamp"`
	BlockStart  int64            `json:"block_start"`
	BlockEnd    int64            `json:"block_end"`
	BlockHeight int64            `json:"block_height"`
	TxHash      string           `json:"tx_hash"`
}

// insert a new SLA rollup record
func (q *Queries) InsertSlaRollup(ctx context.Context, arg InsertSlaRollupParams) (EtlSlaRollup, error) {
	row := q.db.QueryRow(ctx, insertSlaRollup,
		arg.Timestamp,
		arg.BlockStart,
		arg.BlockEnd,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlSlaRollup
	err := row.Scan(
		&i.ID,
		&i.Timestamp,
		&i.BlockStart,
		&i.BlockEnd,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertStorageProof = `-- name: InsertStorageProof :one
insert into etl_storage_proofs (
        height,
        address,
        prover_addresses,
        cid,
        proof_signature,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5, $6, $7)
returning id, height, address, prover_addresses, cid, proof_signature, block_height, tx_hash, created_at, updated_at
`

type InsertStorageProofParams struct {
	Height          int64    `json:"height"`
	Address         string   `json:"address"`
	ProverAddresses []string `json:"prover_addresses"`
	Cid             string   `json:"cid"`
	ProofSignature  []byte   `json:"proof_signature"`
	BlockHeight     int64    `json:"block_height"`
	TxHash          string   `json:"tx_hash"`
}

// insert a new storage proof record
func (q *Queries) InsertStorageProof(ctx context.Context, arg InsertStorageProofParams) (EtlStorageProof, error) {
	row := q.db.QueryRow(ctx, insertStorageProof,
		arg.Height,
		arg.Address,
		arg.ProverAddresses,
		arg.Cid,
		arg.ProofSignature,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlStorageProof
	err := row.Scan(
		&i.ID,
		&i.Height,
		&i.Address,
		&i.ProverAddresses,
		&i.Cid,
		&i.ProofSignature,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertStorageProofVerification = `-- name: InsertStorageProofVerification :one
insert into etl_storage_proof_verifications (
        height,
        proof,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4)
returning id, height, proof, block_height, tx_hash, created_at, updated_at
`

type InsertStorageProofVerificationParams struct {
	Height      int64  `json:"height"`
	Proof       []byte `json:"proof"`
	BlockHeight int64  `json:"block_height"`
	TxHash      string `json:"tx_hash"`
}

// insert a new storage proof verification record
func (q *Queries) InsertStorageProofVerification(ctx context.Context, arg InsertStorageProofVerificationParams) (EtlStorageProofVerification, error) {
	row := q.db.QueryRow(ctx, insertStorageProofVerification,
		arg.Height,
		arg.Proof,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlStorageProofVerification
	err := row.Scan(
		&i.ID,
		&i.Height,
		&i.Proof,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertTransaction = `-- name: InsertTransaction :one
insert into etl_transactions (
        tx_hash,
        block_height,
        index,
        tx_type
    )
values ($1, $2, $3, $4)
returning id, tx_hash, block_height, index, tx_type, created_at, updated_at
`

type InsertTransactionParams struct {
	TxHash      string `json:"tx_hash"`
	BlockHeight int64  `json:"block_height"`
	Index       int64  `json:"index"`
	TxType      string `json:"tx_type"`
}

// insert a new transaction record
func (q *Queries) InsertTransaction(ctx context.Context, arg InsertTransactionParams) (EtlTransaction, error) {
	row := q.db.QueryRow(ctx, insertTransaction,
		arg.TxHash,
		arg.BlockHeight,
		arg.Index,
		arg.TxType,
	)
	var i EtlTransaction
	err := row.Scan(
		&i.ID,
		&i.TxHash,
		&i.BlockHeight,
		&i.Index,
		&i.TxType,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertValidatorDeregistration = `-- name: InsertValidatorDeregistration :one
insert into etl_validator_deregistrations (
        comet_address,
        comet_pubkey,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4)
returning id, comet_address, comet_pubkey, block_height, tx_hash, created_at, updated_at
`

type InsertValidatorDeregistrationParams struct {
	CometAddress string `json:"comet_address"`
	CometPubkey  []byte `json:"comet_pubkey"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// insert a new validator deregistration record
func (q *Queries) InsertValidatorDeregistration(ctx context.Context, arg InsertValidatorDeregistrationParams) (EtlValidatorDeregistration, error) {
	row := q.db.QueryRow(ctx, insertValidatorDeregistration,
		arg.CometAddress,
		arg.CometPubkey,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlValidatorDeregistration
	err := row.Scan(
		&i.ID,
		&i.CometAddress,
		&i.CometPubkey,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertValidatorMisbehaviorDeregistration = `-- name: InsertValidatorMisbehaviorDeregistration :one
insert into etl_validator_misbehavior_deregistrations (
        comet_address,
        pub_key,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4)
returning id, comet_address, pub_key, block_height, tx_hash, created_at, updated_at
`

type InsertValidatorMisbehaviorDeregistrationParams struct {
	CometAddress string `json:"comet_address"`
	PubKey       []byte `json:"pub_key"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// insert a new validator misbehavior deregistration record
func (q *Queries) InsertValidatorMisbehaviorDeregistration(ctx context.Context, arg InsertValidatorMisbehaviorDeregistrationParams) (EtlValidatorMisbehaviorDeregistration, error) {
	row := q.db.QueryRow(ctx, insertValidatorMisbehaviorDeregistration,
		arg.CometAddress,
		arg.PubKey,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlValidatorMisbehaviorDeregistration
	err := row.Scan(
		&i.ID,
		&i.CometAddress,
		&i.PubKey,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertValidatorRegistration = `-- name: InsertValidatorRegistration :one
insert into etl_validator_registrations (
        address,
        endpoint,
        comet_address,
        eth_block,
        node_type,
        spid,
        comet_pubkey,
        voting_power,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
returning id, address, endpoint, comet_address, eth_block, node_type, spid, comet_pubkey, voting_power, block_height, tx_hash, created_at, updated_at
`

type InsertValidatorRegistrationParams struct {
	Address      string `json:"address"`
	Endpoint     string `json:"endpoint"`
	CometAddress string `json:"comet_address"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	Spid         string `json:"spid"`
	CometPubkey  []byte `json:"comet_pubkey"`
	VotingPower  int64  `json:"voting_power"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// insert a new validator registration record
func (q *Queries) InsertValidatorRegistration(ctx context.Context, arg InsertValidatorRegistrationParams) (EtlValidatorRegistration, error) {
	row := q.db.QueryRow(ctx, insertValidatorRegistration,
		arg.Address,
		arg.Endpoint,
		arg.CometAddress,
		arg.EthBlock,
		arg.NodeType,
		arg.Spid,
		arg.CometPubkey,
		arg.VotingPower,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlValidatorRegistration
	err := row.Scan(
		&i.ID,
		&i.Address,
		&i.Endpoint,
		&i.CometAddress,
		&i.EthBlock,
		&i.NodeType,
		&i.Spid,
		&i.CometPubkey,
		&i.VotingPower,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const insertValidatorRegistrationLegacy = `-- name: InsertValidatorRegistrationLegacy :one
insert into etl_validator_registrations_legacy (
        endpoint,
        comet_address,
        eth_block,
        node_type,
        sp_id,
        pub_key,
        power,
        block_height,
        tx_hash
    )
values ($1, $2, $3, $4, $5, $6, $7, $8, $9)
returning id, endpoint, comet_address, eth_block, node_type, sp_id, pub_key, power, block_height, tx_hash, created_at, updated_at
`

type InsertValidatorRegistrationLegacyParams struct {
	Endpoint     string `json:"endpoint"`
	CometAddress string `json:"comet_address"`
	EthBlock     string `json:"eth_block"`
	NodeType     string `json:"node_type"`
	SpID         string `json:"sp_id"`
	PubKey       []byte `json:"pub_key"`
	Power        int64  `json:"power"`
	BlockHeight  int64  `json:"block_height"`
	TxHash       string `json:"tx_hash"`
}

// insert a new legacy validator registration record
func (q *Queries) InsertValidatorRegistrationLegacy(ctx context.Context, arg InsertValidatorRegistrationLegacyParams) (EtlValidatorRegistrationsLegacy, error) {
	row := q.db.QueryRow(ctx, insertValidatorRegistrationLegacy,
		arg.Endpoint,
		arg.CometAddress,
		arg.EthBlock,
		arg.NodeType,
		arg.SpID,
		arg.PubKey,
		arg.Power,
		arg.BlockHeight,
		arg.TxHash,
	)
	var i EtlValidatorRegistrationsLegacy
	err := row.Scan(
		&i.ID,
		&i.Endpoint,
		&i.CometAddress,
		&i.EthBlock,
		&i.NodeType,
		&i.SpID,
		&i.PubKey,
		&i.Power,
		&i.BlockHeight,
		&i.TxHash,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}
